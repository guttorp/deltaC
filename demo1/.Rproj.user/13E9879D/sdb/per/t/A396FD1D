{
    "contents" : "##########################################\n##########  Web Scraping Ideas  ##########\n##########   By: Barb Banbury   ##########\n##########    5 November 2013   ##########\n##########################################\n\n\nlibrary(XML)\nlibrary(ape)\n\n\n###  Scraping html data by hand can be tiresome, but can be done  ###\n\n# Scraping text: download the list of 100 worst invasive species from GISD to working directory\nweb <- \"http://www.issg.org/database/species/search.asp?st=100ss&fr=1&str=&lang=EN\"\nweb2 <- readLines(web)\nweb3 <- web2[grep(\"ListTitle\", web2)]\nInvasiveSp <- rep(NA, length(web3))\nfor(i in sequence(length(web3))){\n  split1 <- strsplit(web3[[i]], \"<i>\", fixed=T)[[1]][2]  #breaks at html italics tag\n  InvasiveSp[i] <- strsplit(split1, \"</i>\", fixed=T)[[1]][1]  #breaks at end tag\n}\n\n\n\n# Scraping tables:  DateLife example\nweb <- \"http://datelife.org/cgi-bin/R/result?input=Rhinoceros_unicornis%2CEquus_caballus%2CMus_musculus&format=html&partial=liberal&useembargoed=yes&uncertainty=100&usetnrs=no&tnrssource=NCB\"\ntables <- readHTMLTable(web)\n#these come in as a list of however many html tables there are on the web, to go through each, use [[]]\ntables[[1]]\ncolnames(tables[[1]])\n#Can then rearrange data however you see fit (changing to numeric, factors, etc.)\n\n#can also grab other bits off this page since it has an API\nread.tree(\"http://datelife.org/cgi-bin/R/result?input=Rhinoceros_unicornis%2CEquus_caballus%2CMus_musculus&format=newickmed&partial=liberal&useembargoed=yes&uncertainty=100\")\n\n\n\n###  Web scraping made easy by API  ###\n\n# rgbif:  http://www.gbif.org/\nlibrary(devtools)\ninstall_github(\"rgbif\", \"ropensci\", ref=\"newapi\")\nlibrary(rgbif)\n\n#Get occurance data and plot on a map\nkey <- gbif_lookup(name=\"Megaptera novaeangliae\", kingdom=\"animalia\")$speciesKey\ndat <- occ_search(taxonKey=key, return=\"data\", limit = 500)\ngbifmap(input=dat, mapdatabase=\"world\")\n\nlibrary(maps)\nlibrary(ggplot2)\ndat <- occ_search(taxonKey=key, country=\"US\", limit=500, return='data')\nworld = map_data(\"world\")\n(ggplot(world, aes(long, lat)) \n  + geom_polygon(aes(group = group), fill = \"white\", color = \"gray40\", size = .2)\n  + geom_jitter(data = dat, aes(dat$longitude, dat$latitude), alpha=0.6, size = 4, color = \"blue\")\n)\n\n\n#rfishbase: http://www.fishbase.org/search.php\nlibrary(rfishbase)\ndata(fishbase)\n\n#Get list of bathydemersal species and download EOL and provider pages\nbathyFish <- which_fish(\"bathydemersal\", using=\"habitat\", fish.data)\nbathyFish <- fish_names(fish.data[bathyFish])\nsex_swap <- which_fish(\"change sex\", using=\"lifecycle\", fish.data)\nafrica <- which_fish(\"Africa\", using=\"distribution\", fish.data)\nfish.data[which(sex_swap)][[1]]\n\n#rvertnet\ninstall_github('rvertnet', 'ropensci')\nlibrary(rvertnet)\n\n#Gather info on what Anoles are in Museums\nvertproviders(grp=\"herp\", t=\"Anolis\")  #check museum providers\nvertoccurrence(grp=\"herp\", t = \"Anolis\", c=\"UCZM\")[, 1:4]  #check specific museums\nvertoccurrence(l=\"Florida\", t=\"Anolis\", num=100) #or check all occurances from Florida\n\n\n\n\n\n#1) Genetic Data\n#rentrez (entrez)\n#rsnps (openSNP data)\n#rflybase (flybase)\n\n#2) Geographic and Climactic Data\n#rgbif (gbif)\n#rnpn (National Phenology Network)\n#rnoaa (NOAA climate data)\n#rWBClimate (world bank climate data)\n\n#3) Phylogenetic Data\n#treebase (treebase)\n\n#4) Data Repository\n#rdryad (dryad)\n\n#5) General information\n#Reol (EOL)\n#rfishbase (fishbase)\n#rvertnet (vertnet)\n#neotoma (Neotoma Paleoecological Data)\n#rebird (eBird)\n#taxsize (lots, but you can search invasive species)\n\n#6) Other\n#rMendeley (Mendeley)\n#rplos (PLOS publishing)\n#rspringer (Springer Publishing)\n#twitteR (twitter)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
    "created" : 1383694380160.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2033459861",
    "id" : "A396FD1D",
    "lastKnownWriteTime" : 1383596366,
    "path" : "~/Downloads/Week5_Web_Interaction 2/WebScraping.R",
    "project_path" : null,
    "properties" : {
    },
    "source_on_save" : false,
    "type" : "r_source"
}